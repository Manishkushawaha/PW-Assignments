{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c1515f61",
   "metadata": {},
   "source": [
    "### Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach?Explain with an example.\n",
    "\n",
    "Ans:Eigenvalues and eigenvectors are fundamental concepts in linear algebra, particularly when dealing with square matrices.\n",
    "\n",
    "Eigenvalues (λ) are scalar values that represent how a linear transformation, represented by a matrix, stretches or compresses a vector in a particular direction. Eigenvectors (v) are the non-zero vectors that remain in the same direction after the transformation, albeit possibly scaled by the corresponding eigenvalue.\n",
    "\n",
    "The Eigen-Decomposition approach decomposes a square matrix into its constituent eigenvalues and eigenvectors. Mathematically, for a square matrix A, the Eigen-Decomposition is represented as:\n",
    "\n",
    "![image.png](attachment:image.png) \n",
    "\n",
    "Where:\n",
    "\n",
    "* A is the original matrix.\n",
    "* Q is a matrix whose columns are the eigenvectors of A.\n",
    "* Λ is a diagonal matrix containing the corresponding eigenvalues.\n",
    "\n",
    "Here's how you can compute the eigenvalues and eigenvectors of a matrix in Python using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdc138e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [4. 2.]\n",
      "Eigenvectors: [[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the matrix\n",
    "A = np.array([[3, 1], [1, 3]])\n",
    "\n",
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "# Print eigenvalues and eigenvectors\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\", eigenvectors)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "4b0c9a89",
   "metadata": {},
   "source": [
    "### Q2. What is eigen decomposition and what is its significance in linear algebra?\n",
    "\n",
    "Ans:Eigen decomposition is a process of decomposing a matrix into a set of eigenvectors and eigenvalues. It is significant in linear algebra because it provides insight into the behavior of linear transformations, allows for the simplification of complex matrix operations, and enables the analysis of dynamic systems through techniques like diagonalization.\n",
    "\n",
    "### Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using theEigen-Decomposition approach? Provide a brief proof to support your answer.\n",
    "\n",
    "Ans:For a square matrix A to be diagonalizable, it must satisfy the following conditions:\n",
    "\n",
    "Algebraic Multiplicity Equals Geometric Multiplicity: The algebraic multiplicity of an eigenvalue must be equal to its geometric multiplicity. Algebraic multiplicity refers to the number of times an eigenvalue appears as a root of the characteristic polynomial of the matrix A, while geometric multiplicity refers to the dimension of the eigenspace corresponding to that eigenvalue.\n",
    "\n",
    "Complete Set of Linearly Independent Eigenvectors: There must be a complete set of linearly independent eigenvectors corresponding to the eigenvalues of the matrix A.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "Let's consider a square matrix A of size n×n with eigenvalues λ1,λ2,...,λn and corresponding eigenvectors v1,v2,...,vn\n",
    "\n",
    "\n",
    "The matrix A is diagonalizable if there exists an invertible matrix P such that ![image.png](attachment:image.png) where D is a diagonal matrix whose diagonal elements are the eigenvalues of A.\n",
    "\n",
    "To prove that A is diagonalizable, we need to show that there exists a full set of linearly independent eigenvectors v1,v2,...,vn corresponding to λ1,λ2 ,...,λn\n",
    "\n",
    "If A is diagonalizable, then the matrix P formed by stacking the eigenvectors v1,v2,...,vn as columns must be invertible. This implies that the columns of P are linearly independent.\n",
    "\n",
    "Moreover, each eigenvalue λi must have a geometric multiplicity equal to its algebraic multiplicity. Geometric multiplicity refers to the number of linearly independent eigenvectors corresponding to λi, and algebraic multiplicity refers to the number of times λi appears as a root of the characteristic polynomial.\n",
    "\n",
    "If all eigenvalues have linearly independent eigenvectors and the number of linearly independent eigenvectors for each eigenvalue matches its algebraic multiplicity, then the matrix A is diagonalizable.\n",
    "\n",
    "### Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach?How is it related to the diagonalizability of a matrix? Explain with an example.\n",
    "\n",
    "Ans:The spectral theorem states that for a symmetric matrix, all eigenvalues are real, and eigenvectors corresponding to distinct eigenvalues are orthogonal. This theorem is crucial in the context of Eigen-Decomposition because it guarantees the existence of a complete set of orthogonal eigenvectors for symmetric matrices, making them diagonalizable.\n",
    "\n",
    "### Q5. How do you find the eigenvalues of a matrix and what do they represent?\n",
    "\n",
    "Ans:Eigenvalues of a matrix A can be found by solving the characteristic equation det(A−λI)=0, where I is the identity matrix. Eigenvalues represent how the matrix stretches or compresses vectors during linear transformations.\n",
    "\n",
    "\n",
    "### Q6. What are eigenvectors and how are they related to eigenvalues?\n",
    "\n",
    "Ans:Eigenvectors are non-zero vectors that, when transformed by a matrix, are scaled by a corresponding eigenvalue. They represent the direction along which the linear transformation acts.\n",
    "\n",
    "### Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?\n",
    "\n",
    "Ans:Eigenvectors represent the directions along which the linear transformation is only stretched or compressed, without changing direction. Eigenvalues represent the scaling factor by which the eigenvectors are stretched or compressed.\n",
    "\n",
    "#### Q8. What are some real-world applications of eigen decomposition?\n",
    "\n",
    "Ans:Real-world applications include:\n",
    "\n",
    "* Image compression using Principal Component Analysis (PCA).\n",
    "* Solving systems of differential equations in physics and engineering.\n",
    "* Data analysis techniques like the Singular Value Decomposition (SVD) for dimensionality reduction.\n",
    "\n",
    "\n",
    "### Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?\n",
    "\n",
    "Ans:Yes, a matrix can have multiple sets of eigenvectors and eigenvalues, especially if it is non-diagonalizable. However, each set of eigenvectors corresponds to its set of eigenvalues.\n",
    "\n",
    "\n",
    "### Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning?Discuss at least three specific applications or techniques that rely on Eigen-Decomposition.\n",
    "\n",
    "Ans:The Eigen-Decomposition approach, which involves decomposing a matrix into its eigenvalues and eigenvectors, is widely used in various applications within data analysis and machine learning. Here are three specific ways in which Eigen-Decomposition is applied:\n",
    "\n",
    "**Principal Component Analysis (PCA):**\n",
    "\n",
    "* PCA is a dimensionality reduction technique that relies on Eigen-Decomposition to identify the principal components (eigenvectors) of a dataset.\n",
    "\n",
    "* By transforming the original features of the dataset into a new set of uncorrelated variables (principal components), PCA helps in reducing the dimensionality of the data while retaining most of its variance.\n",
    "\n",
    "* The eigenvalues associated with the principal components indicate the amount of variance captured by each component, allowing for informed decisions about which components to retain.\n",
    "\n",
    "**Spectral Clustering:**\n",
    "\n",
    "* Spectral clustering is a technique used for clustering data points based on the spectral properties of a similarity matrix.\n",
    "\n",
    "* The Eigen-Decomposition of the Laplacian matrix, derived from the graph representation of the data, helps in identifying the eigenvectors corresponding to the smallest eigenvalues.\n",
    "\n",
    "* These eigenvectors are used to embed the data points into a lower-dimensional space, where clustering algorithms such as k-means can be applied more effectively.\n",
    "\n",
    "**Matrix Factorization Techniques:**\n",
    "\n",
    "Eigen-Decomposition is fundamental in various matrix factorization methods used in machine learning, such as Singular Value Decomposition (SVD) and Non-negative Matrix Factorization (NMF).\n",
    "\n",
    "In SVD, a matrix is decomposed into three matrices: U (left singular vectors), Σ (diagonal matrix of singular values), and Vᵀ (right singular vectors), where U and V are composed of eigenvectors.\n",
    "\n",
    "Similarly, in NMF, the decomposition of a non-negative matrix into two lower-rank matrices relies on optimization techniques that involve Eigen-Decomposition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
